{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "36bd789b-0754-4fb6-98d1-3156864534aa",
    "_uuid": "2b793516-8fde-4e68-b7e3-3623645ba77d"
   },
   "source": [
    "# Importing all the required modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "e3dc8c28-2e2f-44b0-9cff-63f238670994",
    "_kg_hide-output": true,
    "_uuid": "633372d1-166e-4f38-9109-6a5d218e3a2e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Attaching package: 'dplyr'\n",
      "\n",
      "\n",
      "The following objects are masked from 'package:stats':\n",
      "\n",
      "    filter, lag\n",
      "\n",
      "\n",
      "The following objects are masked from 'package:base':\n",
      "\n",
      "    intersect, setdiff, setequal, union\n",
      "\n",
      "\n",
      "Loading required package: NLP\n",
      "\n",
      "\n",
      "Attaching package: 'NLP'\n",
      "\n",
      "\n",
      "The following object is masked from 'package:ggplot2':\n",
      "\n",
      "    annotate\n",
      "\n",
      "\n",
      "Loading required package: koRpus.lang.en\n",
      "\n",
      "Loading required package: koRpus\n",
      "\n",
      "Loading required package: sylly\n",
      "\n",
      "For information on available language packages for 'koRpus', run\n",
      "\n",
      "  available.koRpus.lang()\n",
      "\n",
      "and see ?install.koRpus.lang()\n",
      "\n",
      "\n",
      "\n",
      "Attaching package: 'koRpus'\n",
      "\n",
      "\n",
      "The following object is masked from 'package:tm':\n",
      "\n",
      "    readTagged\n",
      "\n",
      "\n",
      "The following object is masked from 'package:readr':\n",
      "\n",
      "    tokenize\n",
      "\n",
      "\n",
      "Type 'citation(\"pROC\")' for a citation.\n",
      "\n",
      "\n",
      "Attaching package: 'pROC'\n",
      "\n",
      "\n",
      "The following objects are masked from 'package:stats':\n",
      "\n",
      "    cov, smooth, var\n",
      "\n",
      "\n",
      "randomForest 4.6-14\n",
      "\n",
      "Type rfNews() to see new features/changes/bug fixes.\n",
      "\n",
      "\n",
      "Attaching package: 'randomForest'\n",
      "\n",
      "\n",
      "The following object is masked from 'package:ggplot2':\n",
      "\n",
      "    margin\n",
      "\n",
      "\n",
      "The following object is masked from 'package:dplyr':\n",
      "\n",
      "    combine\n",
      "\n",
      "\n",
      "naivebayes 0.9.7 loaded\n",
      "\n",
      "Loading required package: lattice\n",
      "\n",
      "\n",
      "Attaching package: 'igraph'\n",
      "\n",
      "\n",
      "The following object is masked from 'package:tidyr':\n",
      "\n",
      "    crossing\n",
      "\n",
      "\n",
      "The following objects are masked from 'package:dplyr':\n",
      "\n",
      "    as_data_frame, groups, union\n",
      "\n",
      "\n",
      "The following objects are masked from 'package:stats':\n",
      "\n",
      "    decompose, spectrum\n",
      "\n",
      "\n",
      "The following object is masked from 'package:base':\n",
      "\n",
      "    union\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "library(readr)\n",
    "library(dplyr)\n",
    "library(stringr)\n",
    "library(ggplot2)\n",
    "library(tidyr)\n",
    "library(tm)\n",
    "library(textstem) \n",
    "library(tidytext)\n",
    "library(wordcloud2)\n",
    "library(pROC)\n",
    "library(ROCR)\n",
    "library(randomForest)  \n",
    "library(naivebayes)\n",
    "library(caret)\n",
    "library(janeaustenr)\n",
    "library(igraph)\n",
    "library(ggraph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "d33baf89-696d-425e-a859-c4fcc4dbcccd",
    "_uuid": "1645e058-c445-49df-b222-d1268f828970"
   },
   "source": [
    "# Importing required datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "a63758ff-c6c3-49bc-8770-b1f99c9e50bf",
    "_uuid": "87234923-3251-47c8-8ab3-de507bf4c6b8"
   },
   "outputs": [],
   "source": [
    "fake <- read_csv('Fake.csv')\n",
    "true <- read_csv('True.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "head(fake,1)\n",
    "head(true,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "1c99611a-aa9c-4f4a-be90-1d8f76049509",
    "_uuid": "958ee69d-b13a-47c4-b802-f4ffc818ea18"
   },
   "source": [
    "# Data Decription and Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "13d86515-9800-4f33-a520-eb1b0f45bbc6",
    "_uuid": "70c2fe2c-38cb-4688-86e2-b81148d77026"
   },
   "source": [
    "### The data required for this project is present in two datafiles of csv format. The files are namely true.csv and fake.csv. The true.csv files contains news that are true and similarly for Fake.csv which contains fake news."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "f88fc09a-2097-42ad-841f-8e90141ee28a",
    "_uuid": "f27b2e71-3d45-4266-8c57-a16979dd8bdb"
   },
   "source": [
    "### Number of columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "f59f529b-5753-4c15-b8d2-ec33607383f6",
    "_kg_hide-input": true,
    "_uuid": "c4656003-125b-4950-a693-8d14a53c1d3d"
   },
   "outputs": [],
   "source": [
    "print(\"The number of columns in true.csv\")\n",
    "dim(true)\n",
    "print(\"The number of columns in fake.csv\")\n",
    "dim(fake)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "f7453a8e-1666-45f8-87bc-60764896ea93",
    "_uuid": "e457e058-c714-40f4-9d74-f84cafeacf04"
   },
   "outputs": [],
   "source": [
    "barplot(c(nrow(true) , nrow(fake)) , \n",
    "        main=\"Number of rows in each dataset\",\n",
    "        xlab=\"Category\",\n",
    "        ylab=\"Count\",\n",
    "        border=\"red\",\n",
    "        col=\"blue\",\n",
    "       density = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "e3521f11-93e0-48d1-a739-c5e3528d086e",
    "_uuid": "eff4dd06-7120-4a9d-9d0d-6a643185e500"
   },
   "source": [
    "## Both the datasets are balanced."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "6e554369-1fa6-4b99-9507-64943c179a71",
    "_uuid": "10cec426-7f41-4c2f-8681-688d631f6b3f"
   },
   "source": [
    "### Columns datatypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "ffe36ae3-964b-4659-a770-6a1ced55e23c",
    "_uuid": "955ac270-ed1b-4b14-a8af-ab80c39663ce"
   },
   "outputs": [],
   "source": [
    "glimpse(true)\n",
    "glimpse(fake)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "54731919-9156-4a3b-afb5-64841ab537ae",
    "_uuid": "2d1e589b-142d-4318-aafa-839bde40d02a"
   },
   "source": [
    "### Are any NA values present?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "3b93d62b-aefa-4bea-ab92-b08f97c8d7ff",
    "_uuid": "56b28888-4e6a-439d-bd3f-9b40891238aa"
   },
   "outputs": [],
   "source": [
    "sum(is.na(true))\n",
    "sum(is.na(fake))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "479ac260-0df1-4e37-9460-be9916d76fa9",
    "_uuid": "5add6153-88b2-41cc-a1d3-ce24c7313b77"
   },
   "outputs": [],
   "source": [
    "## Percentage of total dataset\n",
    "\n",
    "sum(is.na(true))/nrow(true)*100\n",
    "sum(is.na(fake))/nrow(fake)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "47b582fe-0272-41c9-8bca-084454c5b317",
    "_uuid": "7ded040f-738b-4b69-9b63-f0d3228c1853"
   },
   "source": [
    "### As we can see that NA values are present and when compared to the total numbers of rows they are only 0.004%  and 2.68% of the total dataset. Instead of predicting them we can just drop them because large amount of data is not lost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "e640d49a-077b-42e4-8c21-49d790104eb9",
    "_uuid": "8b338937-a418-4555-804e-1ff1fb968e5a"
   },
   "outputs": [],
   "source": [
    "true <- true %>% drop_na()\n",
    "fake <- fake %>% drop_na()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "333ce9e0-507e-405a-a20a-c560b30ee24d",
    "_uuid": "ef003156-9e9f-44b7-8f52-ec7c16482caa"
   },
   "outputs": [],
   "source": [
    "dim(true)\n",
    "dim(fake)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "57c2c8f8-97c4-45c5-948f-dc8117e001a3",
    "_uuid": "1344ea47-e0ca-4b19-9077-54b5c44c7614"
   },
   "source": [
    "### Summary of datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "4e6d3337-4739-4a52-819e-b62e3a4cd0ed",
    "_uuid": "f47cbb3a-e5d4-4de5-8bbf-192af25512e3"
   },
   "outputs": [],
   "source": [
    "summary(fake)\n",
    "summary(true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "458efaba-bb48-48c1-9442-c25cc7b39d85",
    "_uuid": "bd20efbc-7599-46f2-a7c3-cfb57223e308"
   },
   "source": [
    "# Merging datasets for further preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "a74ff81f-9eaf-4f0d-af33-0e8d6cf1ef0c",
    "_uuid": "11fd2e87-398b-49cc-b0e7-278b5e53878f"
   },
   "outputs": [],
   "source": [
    "fake$y <- 0\n",
    "true$y <- 1\n",
    "news <- bind_rows(fake, true)\n",
    "\n",
    "## since the y column is of categorical type and the models will consider it of numerical if we do not convert it to factor.\n",
    "## The same applies for the subject columns\n",
    "news$y <- as.factor(news$y)\n",
    "news$subject <- as.factor(news$subject)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "ffe47d5c-445e-4470-b960-0799d49e3b45",
    "_uuid": "0f478a8c-7182-4036-a75a-c71d894ea97e"
   },
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "35803cf5-e344-41ed-81c8-139e4edc88c9",
    "_uuid": "225f1169-d527-4355-bae6-4c1ba67f74ca"
   },
   "outputs": [],
   "source": [
    "# News count by each Subject\n",
    "news %>% group_by(subject) %>% count() %>% arrange(desc(n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b67151a2-7b10-4435-ad7b-6e656e906686",
    "_uuid": "6a78933c-88cd-44ed-b314-62b5fcf3a06c"
   },
   "outputs": [],
   "source": [
    "news %>%\n",
    "  group_by(subject) %>%\n",
    "  count(sort = TRUE) %>%\n",
    "  rename(freq = n) %>%\n",
    "  ggplot(aes(x = reorder(subject, -freq), y = freq)) + \n",
    "  geom_bar(stat = 'identity', fill = 'skyblue') +\n",
    "  theme_classic() +\n",
    "  xlab('Subject') +\n",
    "  ylab('frequency') +\n",
    "  geom_text(aes(label = freq), vjust = 1.2, fontface = 'bold') +\n",
    "  theme(axis.title = element_text(face = 'bold', size = 15),\n",
    "        axis.text = element_text(size = 13, angle = 90))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "a71d85bd-173a-4c31-9d30-c810a134eab0",
    "_uuid": "323f39b0-d4f3-4436-a103-902c9a987ad7"
   },
   "outputs": [],
   "source": [
    "## Categoty wise news subject plot\n",
    "\n",
    "ggplot(news, aes(x = subject , fill = y)) +\n",
    "  geom_bar(position = 'dodge', alpha = 0.6) +\n",
    "  theme_classic() +\n",
    "  theme(axis.title = element_text(face = 'bold', size = 15),\n",
    "        axis.text = element_text(size = 13, angle = 90))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "24c786b2-1321-4432-80e3-e18800539679",
    "_uuid": "5e30d1e4-c17d-4207-a1fa-7abaac1709f7"
   },
   "source": [
    "## A news article is the combination of its heading and the text written below the heading. So we merge the title and text column into one. Reducing the dimension of the dataset. \n",
    "\n",
    "## We can also see that the subject column is biased in nature and will lead to decreased accuracy. So we drop that column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "93a2f2dc-cf8a-4851-b581-fc6d44c45204",
    "_uuid": "2b9411bb-152f-442b-8202-9cee10f8fe4b"
   },
   "outputs": [],
   "source": [
    "y = news$y\n",
    "news$text <- paste(news$title , news$text , sep = ' ')\n",
    "news <- cbind(news[\"text\"] , y)\n",
    "glimpse(news)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "37596506-991a-4afb-a2b4-33499991d4ce",
    "_uuid": "9dd72834-0d63-4900-a099-010d1f6372e7"
   },
   "source": [
    "# N-Gram Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "7cb98c33-c2a7-4157-ba9a-1350aa54216f",
    "_uuid": "53f894d4-b953-4ac9-837f-dc1da660baf4"
   },
   "source": [
    "## Uni Gram Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b2dc1ba9-7f67-4f07-b2ee-25fff22977a3",
    "_uuid": "95f13f88-b03b-4ca4-8add-60cc854961d0"
   },
   "outputs": [],
   "source": [
    "tokeniztion_df <- news %>% unnest_tokens(word, text)\n",
    "tokeniztion_df <- tokeniztion_df %>% anti_join(stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "194af142-e2d8-45e5-a0d2-f646475cbb01",
    "_uuid": "7292e62b-9ab2-4df4-9139-5b99c9a146f8"
   },
   "outputs": [],
   "source": [
    "tokeniztion_df %>% count(word, sort = TRUE) %>% filter(n > 25000) %>% mutate(word = reorder(word, n)) %>%\n",
    "  ggplot(aes(n, word)) +\n",
    "  geom_col() +\n",
    "  labs(y = NULL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Unigram - Fake_News\n",
    "tokeniztion_df_fake <- fake_news %>% unnest_tokens(word, text)\n",
    "tokeniztion_df_fake <- tokeniztion_df_fake %>% anti_join(stop_words)\n",
    "tokeniztion_df_fake %>% count(word, sort = TRUE) %>% filter(n > 10000) %>% mutate(word = reorder(word, n)) %>%\n",
    "  ggplot(aes(n, word , fill = n)) +\n",
    "  geom_col() +\n",
    "  labs(y = NULL) +\n",
    "  theme_minimal()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Unigram - True_News\n",
    "tokeniztion_df_true <- true_news %>% unnest_tokens(word, text)\n",
    "tokeniztion_df_true <- tokeniztion_df_true %>% anti_join(stop_words)\n",
    "tokeniztion_df_true %>% count(word, sort = TRUE) %>% filter(n > 10000) %>% mutate(word = reorder(word, n)) %>%\n",
    "  ggplot(aes(n, word,fill = n)) +\n",
    "  geom_col() +\n",
    "  labs(y = NULL)+\n",
    "  theme_minimal()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "83757fed-3f09-4af9-942b-ad21f1db701b",
    "_uuid": "d7ba1f9c-2da5-4c1d-a774-d6dfb193a9bc"
   },
   "source": [
    "## Bi Gram Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "a494964c-e4d5-49e0-b4dd-d6f0b2ba05bf",
    "_uuid": "3e37bc50-8ac8-4a34-ac1a-a5879a57afde"
   },
   "outputs": [],
   "source": [
    "fake_news <- news%>%filter(y == 0)\n",
    "true_news <- news%>%filter(y == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "5abf6a4a-4a59-4feb-8cd8-617acf6ae4a6",
    "_uuid": "72c95ee2-3889-44b5-9324-3ff62ac155ab"
   },
   "outputs": [],
   "source": [
    "df_bigrams <-  fake_news %>% unnest_tokens(bigram, text, token = \"ngrams\", n = 2)\n",
    "bigrams_separated <- df_bigrams %>% separate(bigram, c(\"word1\", \"word2\"), sep = \" \") %>% filter(!word1 %in% stop_words$word) %>% filter(!word2 %in% stop_words$word)\n",
    "bigram_counts <- bigrams_separated %>%  count(word1, word2, sort = TRUE)\n",
    "bigram_graph <- bigram_counts %>% filter(n > 1000) %>% graph_from_data_frame()\n",
    "set.seed(2017)\n",
    "ggraph(bigram_graph, layout = \"fr\") +\n",
    "  geom_edge_link() +\n",
    "  geom_node_point() +\n",
    "  geom_node_text(aes(label = name), vjust = 1, hjust = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "c6ee2a35-a528-4f66-8f54-72a13467060a",
    "_uuid": "908d5c99-e13b-4a3f-b131-4fab35b3f838"
   },
   "outputs": [],
   "source": [
    "fak_bigram <- data.frame(word <- paste(bigram_counts$word1 , bigram_counts$word2 , sep = \" \"))\n",
    "fak_bigram$n <- bigram_counts$n\n",
    "fak_bigram <- fak_bigram %>% filter(n > 1000)\n",
    "names(fak_bigram) <- c(\"word\" , \"n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "250e3400-c2e2-4ad4-8d82-256bae3886a1",
    "_uuid": "b58693e0-8d7f-4ec8-8629-d66e7c19c6eb"
   },
   "outputs": [],
   "source": [
    "fak_bigram %>% arrange(desc(n)) %>% mutate(word = reorder(word, n)) %>%\n",
    "  ggplot(aes(n, word,fill = n)) +\n",
    "  geom_col() +\n",
    "  labs(y = NULL) + \n",
    "  theme_minimal()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "21fb9d42-3506-4316-922b-47b4caabff3d",
    "_uuid": "8f9886a9-8ec6-4f1e-9e3a-777d5aa6936b"
   },
   "outputs": [],
   "source": [
    "tdf_bigrams <-  true_news %>% unnest_tokens(bigram, text, token = \"ngrams\", n = 2)\n",
    "tbigrams_separated <- tdf_bigrams %>% separate(bigram, c(\"word1\", \"word2\"), sep = \" \") %>% filter(!word1 %in% stop_words$word) %>% filter(!word2 %in% stop_words$word)\n",
    "tbigram_counts <- tbigrams_separated %>%  count(word1, word2, sort = TRUE)\n",
    "tbigram_graph <- tbigram_counts %>% filter(n > 1000) %>% graph_from_data_frame()\n",
    "set.seed(2017)\n",
    "ggraph(tbigram_graph, layout = \"fr\") +\n",
    "  geom_edge_link() +\n",
    "  geom_node_point() +\n",
    "  geom_node_text(aes(label = name), vjust = 1, hjust = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "54670ee0-ced0-41cd-8e90-f2eb95ca782c",
    "_uuid": "9649d722-9496-49af-9cb8-baf44e47707a"
   },
   "outputs": [],
   "source": [
    "tru_bigram <- data.frame(paste(tbigram_counts$word1 , tbigram_counts$word2 , sep = \" \"))\n",
    "tru_bigram$n <- tbigram_counts$n\n",
    "ttru_bigram <- tru_bigram %>% filter(n > 1200)\n",
    "names(ttru_bigram) <- c(\"word\" , \"n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "e84cf665-ee95-4cb2-b343-8487081e1d11",
    "_uuid": "df268a5b-d1cb-406e-9f95-bca73bc3ea45"
   },
   "outputs": [],
   "source": [
    "ttru_bigram %>% arrange(desc(n)) %>% mutate(word = reorder(word, n)) %>%\n",
    "  ggplot(aes(n, word , fill = n)) +\n",
    "  geom_col() +\n",
    "  labs(y = NULL) + \n",
    "  theme_minimal()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "200bba10-941c-4ce0-909b-8e89f9561be0",
    "_uuid": "a06a02e3-e982-4384-9e2f-0b5740049ef6"
   },
   "source": [
    "## We implement various test preprocessing technique\n",
    "\n",
    "* to lowercase\n",
    "* remove numbers\n",
    "* remove punctutaions\n",
    "* remove stopwords \n",
    "* remove whitespaces\n",
    "* Lemmatization\n",
    "* Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(readr)\n",
    "library(dplyr)\n",
    "library(stringr)\n",
    "library(ggplot2)\n",
    "library(tidyr)\n",
    "library(tm)\n",
    "library(textstem) \n",
    "library(tidytext)\n",
    "library(wordcloud2)\n",
    "library(pROC)\n",
    "library(ROCR)\n",
    "library(randomForest)  \n",
    "library(naivebayes)\n",
    "library(caret)\n",
    "library(janeaustenr)\n",
    "library(igraph)\n",
    "library(ggraph)\n",
    "\n",
    "## Importing data\n",
    "fake <- read_csv('../input/fake-and-real-news-dataset/Fake.csv')\n",
    "true <- read_csv('../input/fake-and-real-news-dataset/True.csv')\n",
    "##Dropping NA rows\n",
    "true_news <- true_news %>% drop_na()\n",
    "fake_news <- fake_news %>% drop_na()\n",
    "## Merging Datasets\n",
    "fake_news$type <- 0\n",
    "true_news$type <- 1\n",
    "news <- bind_rows(fake_news, true_news)\n",
    "news$type <- as.factor(news$type)\n",
    "type = news$type\n",
    "news$text <- paste(news$title , news$text , sep = ' ')\n",
    "news <- cbind(news[\"text\"] , type)\n",
    "data <- news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data <- news[sample(nrow(data)),]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  ##Preprocessing\n",
    "  doc <- VCorpus(VectorSource(data$text))\n",
    "  doc <- tm_map(doc, removePunctuation)\n",
    "  doc <- tm_map(doc, removeNumbers)\n",
    "  doc <- tm_map(doc, content_transformer(tolower))\n",
    "  doc <- tm_map(doc, removeWords, stopwords(\"english\"))\n",
    "  doc <- tm_map(doc, stripWhitespace)\n",
    "  doc <- tm_map(doc, content_transformer(lemmatize_strings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  ## Data Preparation\n",
    "  dtm <- DocumentTermMatrix(doc)\n",
    "  dtm_clean <- removeSparseTerms(dtm, sparse = 0.99)\n",
    "  dtm_mat <- as.matrix(dtm_clean)\n",
    "  y_prediction = data$type\n",
    "  dtm_mat <- cbind(dtm_mat,y_prediction)\n",
    "  dtm_df <- as.data.frame(dtm_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " summary(dtm_df$y_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " dtm_df$y_prediction <- ifelse(dtm_df$y_prediction == 2, 1, 0)\n",
    " dtm_df$y_prediction <- as.factor(dtm_df$y_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  ## Train Test Split\n",
    "  set.seed(2020)\n",
    "  index <- sample(nrow(dtm_df), nrow(dtm_df)*0.8, replace = FALSE)\n",
    "  train_set <- dtm_df[index,]\n",
    "  test_set <- dtm_df[-index,]\n",
    "  names(train_set) <- make.names(names(train_set))\n",
    "  names(test_set) <- make.names(names(test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "3d460c8d-0d19-4ede-961c-6ac4468abf97",
    "_uuid": "63fe385c-4e96-4722-8188-811ea4339332"
   },
   "outputs": [],
   "source": [
    "  ## Fitting Model\n",
    "  #Random Forest\n",
    "  k <- round(sqrt(ncol(train_set)-1))\n",
    "  clf_rf <- randomForest(formula = y_prediction ~ .,data = train_set,ntree = 5 ,mtry = k,method = 'class')\n",
    "  \n",
    "  #Naive Bayes\n",
    "  clf_nb <- naive_bayes(y_prediction ~ ., data = train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  ##Meta Classifier Stacking\n",
    "  # Predicted values\n",
    "  train_set$pred_nb <- as.factor(predict(clf_nb, type = 'class'))\n",
    "  train_set$pred_rf <- as.factor(predict(clf_rf, type = 'response'))\n",
    "  \n",
    "  # Predicted Values for test set\n",
    "  test_set$pred_nb <- as.factor(predict(clf_nb, newdata = test_set))\n",
    "  test_set$pred_rf <- as.factor(predict(clf_rf, newdata = test_set, type = 'response'))\n",
    "  \n",
    "  #Stacking\n",
    "  train_set <- train_set[c(\"pred_nb\" , \"pred_rf\" , \"y_prediction\")]\n",
    "  test_set <-  test_set[c(\"pred_nb\" , \"pred_rf\" , \"y_prediction\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " ##Logistics Regression\n",
    "  clf_lr <- glm(formula = y_prediction~.,  data = train_set, family=binomial(link=\"logit\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  test_set$pred_lr <- predict(clf_lr, newdata = test_set, type = 'response')\n",
    "  test_set$pred_lr <- ifelse(test_set$pred_lr > 0.5,1,0)\n",
    "  test_set$pred_lr <- as.factor(test_set$pred_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confussion Matrix\n",
    "conf <- confusionMatrix(reference = test_set$y_prediction, data = test_set$pred_lr)\n",
    "conf_nb <- caret::confusionMatrix(test_set$y_prediction, test_set$pred_nb)\n",
    "conf_rf <- caret::confusionMatrix(test_set$y_prediction, test_set$pred_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_confusion_matrix(conf)\n",
    "draw_confusion_matrix(conf_nb)\n",
    "draw_confusion_matrix(conf_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_confusion_matrix <- function(cm) {\n",
    "  \n",
    "  layout(matrix(c(1,1,2)))\n",
    "  par(mar=c(2,2,2,2))\n",
    "  plot(c(100, 345), c(300, 450), type = \"n\", xlab=\"\", ylab=\"\", xaxt='n', yaxt='n')\n",
    "  t <- deparse(substitute(cm))\n",
    "  title(paste0('CONFUSION MATRIX',t,sep = \"  \"), cex.main=2)\n",
    "  \n",
    "  # create the matrix \n",
    "  rect(150, 430, 240, 370, col='#3F97D0')\n",
    "  text(195, 435, 'Class1', cex=1.2)\n",
    "  rect(250, 430, 340, 370, col='#F7AD50')\n",
    "  text(295, 435, 'Class2', cex=1.2)\n",
    "  text(125, 370, 'Predicted', cex=1.3, srt=90, font=2)\n",
    "  text(245, 450, 'Actual', cex=1.3, font=2)\n",
    "  rect(150, 305, 240, 365, col='#F7AD50')\n",
    "  rect(250, 305, 340, 365, col='#3F97D0')\n",
    "  text(140, 400, 'Class1', cex=1.2, srt=90)\n",
    "  text(140, 335, 'Class2', cex=1.2, srt=90)\n",
    "  \n",
    "  # add in the cm results \n",
    "  res <- as.numeric(cm$table)\n",
    "  text(195, 400, res[1], cex=1.6, font=2, col='white')\n",
    "  text(195, 335, res[2], cex=1.6, font=2, col='white')\n",
    "  text(295, 400, res[3], cex=1.6, font=2, col='white')\n",
    "  text(295, 335, res[4], cex=1.6, font=2, col='white')\n",
    "  \n",
    "  # add in the specifics \n",
    "  plot(c(100, 0), c(100, 0), type = \"n\", xlab=\"\", ylab=\"\", main = \"DETAILS\", xaxt='n', yaxt='n')\n",
    "  text(10, 85, names(cm$byClass[1]), cex=1.2, font=2)\n",
    "  text(10, 70, round(as.numeric(cm$byClass[1]), 3), cex=1.2)\n",
    "  text(30, 85, names(cm$byClass[2]), cex=1.2, font=2)\n",
    "  text(30, 70, round(as.numeric(cm$byClass[2]), 3), cex=1.2)\n",
    "  text(50, 85, names(cm$byClass[5]), cex=1.2, font=2)\n",
    "  text(50, 70, round(as.numeric(cm$byClass[5]), 3), cex=1.2)\n",
    "  text(70, 85, names(cm$byClass[6]), cex=1.2, font=2)\n",
    "  text(70, 70, round(as.numeric(cm$byClass[6]), 3), cex=1.2)\n",
    "  text(90, 85, names(cm$byClass[7]), cex=1.2, font=2)\n",
    "  text(90, 70, round(as.numeric(cm$byClass[7]), 3), cex=1.2)\n",
    "  \n",
    "  # add in the accuracy information \n",
    "  text(30, 35, names(cm$overall[1]), cex=1.5, font=2)\n",
    "  text(30, 20, round(as.numeric(cm$overall[1]), 3), cex=1.4)\n",
    "  text(70, 35, names(cm$overall[2]), cex=1.5, font=2)\n",
    "  text(70, 20, round(as.numeric(cm$overall[2]), 3), cex=1.4)\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.0.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
